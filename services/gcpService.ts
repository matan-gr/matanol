
import { GceResource, ResourceType, ProvisioningModel, LogEntry, QuotaEntry } from '../types';

const BASE_URL = 'https://compute.googleapis.com/compute/v1/projects';
const RUN_BASE_URL = 'https://run.googleapis.com/v2/projects';
const SQL_ADMIN_URL = 'https://sqladmin.googleapis.com/sql/v1beta4/projects';
const LOGGING_URL = 'https://logging.googleapis.com/v2/entries:list';

// --- Resilience Utilities ---

/**
 * Parses GCP error responses into user-friendly messages.
 */
const parseGcpError = async (response: Response): Promise<string> => {
  try {
    const errorData = await response.json();
    if (errorData?.error) {
      const code = errorData.error.code || response.status;
      const mainMsg = errorData.error.message;
      const details = errorData.error.errors?.map((e: any) => e.message).join('; ');
      
      if (code === 403) return `Access Denied (403): ${mainMsg}. Verify API permissions.`;
      if (code === 401) return `Authentication Failed (401): Session expired. Please reconnect.`;
      if (code === 429) return `Quota Exceeded (429): API rate limit reached. Retrying automatically...`;
      if (code === 412) return `Conflict (412): Resource was modified by another process. Please refresh.`;
      
      return details && details !== mainMsg ? `${mainMsg} (${details})` : mainMsg;
    }
    return `HTTP ${response.status}: ${response.statusText}`;
  } catch (e) {
    return `Network Error: ${response.status} ${response.statusText}`;
  }
};

/**
 * Performs a fetch with Exponential Backoff for 429 and 5xx errors.
 * Base delay: 1s, Max retries: 3.
 * Enforces NO CACHE to ensure real-time data accuracy.
 */
const fetchWithBackoff = async (
  url: string, 
  options: RequestInit, 
  retries = 3, 
  backoff = 1000
): Promise<Response> => {
  const headers = new Headers(options.headers);

  const finalOptions: RequestInit = {
    ...options,
    headers,
    cache: 'no-store', 
    mode: 'cors',      
  };

  try {
    const response = await fetch(url, finalOptions);

    if (response.ok || (response.status < 500 && response.status !== 429)) {
      return response;
    }

    if (retries > 0) {
      console.warn(`Request failed (${response.status}). Retrying in ${backoff}ms...`);
      await new Promise(resolve => setTimeout(resolve, backoff));
      return fetchWithBackoff(url, finalOptions, retries - 1, backoff * 2);
    }

    return response;
  } catch (error) {
    if (retries > 0) {
      console.warn(`Network error. Retrying in ${backoff}ms...`, error);
      await new Promise(resolve => setTimeout(resolve, backoff));
      return fetchWithBackoff(url, finalOptions, retries - 1, backoff * 2);
    }
    throw error;
  }
};

// --- API Implementation ---

const fetchAggregatedResource = async (
  projectId: string,
  accessToken: string,
  resourcePath: string,
  fields: string,
  mapper: (item: any, zone: string) => GceResource
): Promise<GceResource[]> => {
  let resources: GceResource[] = [];
  let nextPageToken: string | undefined = undefined;

  try {
    do {
      const baseUrl = `${BASE_URL}/${projectId}/aggregated/${resourcePath}`;
      const url = new URL(baseUrl);
      
      if (nextPageToken) url.searchParams.append('pageToken', nextPageToken);
      url.searchParams.append('maxResults', '500');
      url.searchParams.append('fields', fields); 

      const response = await fetchWithBackoff(url.toString(), {
        headers: { Authorization: `Bearer ${accessToken}` },
      });

      if (!response.ok) {
        const errorMessage = await parseGcpError(response);
        throw new Error(errorMessage);
      }

      const data = await response.json();
      nextPageToken = data.nextPageToken;

      if (data.items) {
        for (const [scope, scopeData] of Object.entries(data.items)) {
          const scopeName = scope.replace('zones/', '').replace('regions/', '');
          if ((scopeData as any).warning) continue; 

          const items = (scopeData as any)[resourcePath]; 
          if (items && Array.isArray(items)) {
            items.forEach((item: any) => {
              try {
                resources.push(mapper(item, scopeName));
              } catch (err) {
                console.warn(`Failed to parse ${resourcePath} item`, item, err);
              }
            });
          }
        }
      }
    } while (nextPageToken);
  } catch (error) {
    throw error;
  }
  return resources;
};

const fetchGlobalResourceList = async (
  projectId: string,
  accessToken: string,
  resourcePath: string,
  fields: string,
  mapper: (item: any) => GceResource
): Promise<GceResource[]> => {
  let resources: GceResource[] = [];
  let nextPageToken: string | undefined = undefined;

  try {
    do {
      const url = new URL(`${BASE_URL}/${projectId}/global/${resourcePath}`);
      if (nextPageToken) url.searchParams.append('pageToken', nextPageToken);
      
      url.searchParams.append('maxResults', '500');
      url.searchParams.append('fields', fields); 

      const response = await fetchWithBackoff(url.toString(), {
        headers: { Authorization: `Bearer ${accessToken}` },
      });

      if (!response.ok) {
        if (response.status === 403) {
            console.warn(`Access denied for ${resourcePath}, returning empty list.`);
            return [];
        }
        const errorMessage = await parseGcpError(response);
        throw new Error(errorMessage);
      }

      const data = await response.json();
      nextPageToken = data.nextPageToken;

      if (data.items && Array.isArray(data.items)) {
        data.items.forEach((item: any) => {
          try {
            resources.push(mapper(item));
          } catch (err) {
            console.warn(`Failed to parse ${resourcePath} item`, err);
          }
        });
      }
    } while (nextPageToken);
  } catch (error: any) {
    if (error.message && error.message.includes('401')) throw error;
    console.warn(`Fetch warning for ${resourcePath}:`, error);
    return [];
  }
  return resources;
};

// Discovery logic to find active Cloud Run regions
const fetchAvailableRegions = async (projectId: string, accessToken: string): Promise<string[]> => {
  try {
    const url = `${BASE_URL}/${projectId}/regions`;
    const response = await fetchWithBackoff(url, {
      headers: { Authorization: `Bearer ${accessToken}` },
    });
    
    if (!response.ok) return ['us-central1']; // Fallback

    const data = await response.json();
    if (data.items) {
      return data.items.map((i: any) => i.name);
    }
  } catch (e) {
    console.warn("Failed to discover regions, using defaults", e);
  }
  return ['us-central1', 'us-east1', 'europe-west1', 'asia-northeast1'];
};

const fetchCloudRunServices = async (
  projectId: string,
  accessToken: string
): Promise<GceResource[]> => {
  // Dynamically fetch regions first to ensure we catch all services
  const regions = await fetchAvailableRegions(projectId, accessToken);
  const resources: GceResource[] = [];
  
  // Fetch regions in parallel but limit concurrency if needed (browsers handle simple Promise.all fine for <50 reqs)
  await Promise.all(regions.map(async (region) => {
    try {
      const url = `${RUN_BASE_URL}/${projectId}/locations/${region}/services`;
      const response = await fetchWithBackoff(url, {
        headers: { Authorization: `Bearer ${accessToken}` },
      });

      if (!response.ok) {
        // 403/404 on specific region is fine, likely API not enabled in that region or region restricted
        if (response.status === 401) throw new Error("401"); 
        return; 
      }

      const data = await response.json();
      if (data.services && Array.isArray(data.services)) {
        data.services.forEach((svc: any) => {
          resources.push({
            id: svc.name,
            name: svc.name.split('/').pop(),
            type: 'CLOUD_RUN',
            zone: region,
            status: 'READY',
            creationTimestamp: svc.createTime,
            provisioningModel: 'STANDARD',
            url: svc.uri,
            labels: svc.labels || {},
            labelFingerprint: svc.etag || '',
            history: []
          });
        });
      }
    } catch (e: any) {
      if (e.message === '401') throw new Error("Authentication Failed (401)");
      // Silent fail for regions without Cloud Run enabled
    }
  }));

  return resources;
};

const fetchCloudSqlInstances = async (
  projectId: string,
  accessToken: string
): Promise<GceResource[]> => {
  const resources: GceResource[] = [];
  try {
    const url = `${SQL_ADMIN_URL}/${projectId}/instances`;
    const response = await fetchWithBackoff(url, {
      headers: { Authorization: `Bearer ${accessToken}` },
    });

    if (!response.ok) {
      if (response.status === 401) throw new Error("401");
      console.warn('Cloud SQL API access failed or not enabled.');
      return [];
    }

    const data = await response.json();
    if (data.items && Array.isArray(data.items)) {
      data.items.forEach((instance: any) => {
        const zone = instance.gceZone || instance.region || 'global';
        const ips = instance.ipAddresses?.map((ip: any) => ({
          network: 'CloudSQL',
          internal: ip.type === 'PRIVATE' ? ip.ipAddress : '',
          external: ip.type === 'PRIMARY' ? ip.ipAddress : undefined
        })).filter((i: any) => i.internal || i.external) || [];

        resources.push({
          id: instance.name, // SQL instances are project-unique by name
          name: instance.name,
          type: 'CLOUD_SQL',
          zone: zone,
          machineType: instance.settings?.tier || 'db-custom',
          databaseVersion: instance.databaseVersion,
          status: instance.state || 'UNKNOWN',
          creationTimestamp: instance.createTime || new Date().toISOString(), // Fallback if missing
          provisioningModel: 'STANDARD',
          labels: instance.settings?.userLabels || {},
          labelFingerprint: instance.etag || '',
          ips: ips,
          history: []
        });
      });
    }
  } catch (error: any) {
    if (error.message === '401') throw error;
    console.warn("Failed to fetch Cloud SQL instances:", error);
  }
  return resources;
};

export const fetchAllResources = async (
  projectId: string,
  accessToken: string
): Promise<GceResource[]> => {
  
  // 1. Instances
  const instanceFields = `items/*/instances(id,name,machineType,status,creationTimestamp,scheduling/provisioningModel,disks(deviceName,diskSizeGb,type,boot),networkInterfaces(network,networkIP,accessConfigs/natIP),labels,labelFingerprint),nextPageToken`;
  const instancesPromise = fetchAggregatedResource(
    projectId, accessToken, 'instances', instanceFields,
    (inst, zone) => {
      const machineType = inst.machineType ? inst.machineType.split('/').pop() : 'unknown';
      const provisioning: ProvisioningModel = inst.scheduling?.provisioningModel === 'SPOT' ? 'SPOT' : 'STANDARD';
      const disks = inst.disks?.map((d: any) => ({
        deviceName: d.deviceName,
        sizeGb: parseInt(d.diskSizeGb || '0', 10),
        type: d.type || 'PERSISTENT',
        boot: !!d.boot
      })) || [];
      const ips = inst.networkInterfaces?.map((ni: any) => ({
        network: ni.network?.split('/').pop() || 'default',
        internal: ni.networkIP,
        external: ni.accessConfigs?.[0]?.natIP
      })) || [];

      return {
          id: inst.id,
          name: inst.name,
          type: 'INSTANCE',
          zone: zone,
          machineType: machineType,
          status: inst.status || 'UNKNOWN',
          creationTimestamp: inst.creationTimestamp,
          provisioningModel: provisioning,
          labels: inst.labels || {},
          labelFingerprint: inst.labelFingerprint || '',
          disks, ips, history: []
      };
    }
  );

  // 2. Disks
  const diskFields = `items/*/disks(id,name,sizeGb,status,creationTimestamp,labels,labelFingerprint),nextPageToken`;
  const disksPromise = fetchAggregatedResource(
    projectId, accessToken, 'disks', diskFields,
    (disk, zone) => ({
      id: disk.id,
      name: disk.name,
      type: 'DISK',
      zone: zone,
      sizeGb: disk.sizeGb,
      status: disk.status || 'READY',
      creationTimestamp: disk.creationTimestamp,
      provisioningModel: 'STANDARD',
      labels: disk.labels || {},
      labelFingerprint: disk.labelFingerprint || '',
      history: []
    })
  );

  // 3. Images
  const imageFields = `items(id,name,diskSizeGb,status,creationTimestamp,labels,labelFingerprint),nextPageToken`;
  const imagesPromise = fetchGlobalResourceList(
    projectId, accessToken, 'images', imageFields,
    (img) => ({
      id: img.id,
      name: img.name,
      type: 'IMAGE',
      zone: 'global',
      sizeGb: img.diskSizeGb,
      status: img.status || 'READY',
      creationTimestamp: img.creationTimestamp,
      provisioningModel: 'STANDARD',
      labels: img.labels || {},
      labelFingerprint: img.labelFingerprint || '',
      history: []
    })
  );

  // 4. Snapshots
  const snapshotFields = `items(id,name,diskSizeGb,status,creationTimestamp,labels,labelFingerprint),nextPageToken`;
  const snapshotsPromise = fetchGlobalResourceList(
    projectId, accessToken, 'snapshots', snapshotFields,
    (snap) => ({
      id: snap.id,
      name: snap.name,
      type: 'SNAPSHOT',
      zone: 'global',
      sizeGb: snap.diskSizeGb,
      status: snap.status || 'READY',
      creationTimestamp: snap.creationTimestamp,
      provisioningModel: 'STANDARD',
      labels: snap.labels || {},
      labelFingerprint: snap.labelFingerprint || '',
      history: []
    })
  );

  // 5. Cloud Run
  const cloudRunPromise = fetchCloudRunServices(projectId, accessToken);

  // 6. Cloud SQL
  const cloudSqlPromise = fetchCloudSqlInstances(projectId, accessToken);

  // Execute all, but catch individual errors to identify 401s vs partial failures
  const results = await Promise.allSettled([
    instancesPromise, disksPromise, imagesPromise, snapshotsPromise, cloudRunPromise, cloudSqlPromise
  ]);

  const resources: GceResource[] = [];
  const errors: any[] = [];

  results.forEach(result => {
    if (result.status === 'fulfilled') {
      resources.push(...result.value);
    } else {
      errors.push(result.reason);
    }
  });

  if (errors.length > 0) {
    // Detect 401 Authentication Failure (critical)
    const authError = errors.find(e => e.message && e.message.includes('401'));
    if (authError) {
       throw authError; // Rethrow 401 to trigger logout
    }

    // If all failed, throw the first error
    if (resources.length === 0) {
      throw errors[0];
    }
    
    // Partial failure logging
    console.warn("Partial inventory loading failure:", errors.map(e => e.message));
  }
  
  return resources;
};

export const updateResourceLabels = async (
  projectId: string,
  accessToken: string,
  resource: GceResource,
  newLabels: Record<string, string>
) => {
  let url = '';
  let method = 'POST';
  let body: any = {
    labels: newLabels,
    labelFingerprint: resource.labelFingerprint
  };
  
  if (resource.type === 'INSTANCE') {
    url = `${BASE_URL}/${projectId}/zones/${resource.zone}/instances/${resource.name}/setLabels`;
  } else if (resource.type === 'DISK') {
    url = `${BASE_URL}/${projectId}/zones/${resource.zone}/disks/${resource.name}/setLabels`;
  } else if (resource.type === 'IMAGE') {
    url = `${BASE_URL}/${projectId}/global/images/${resource.name}/setLabels`;
  } else if (resource.type === 'SNAPSHOT') {
    url = `${BASE_URL}/${projectId}/global/snapshots/${resource.name}/setLabels`;
  } else if (resource.type === 'CLOUD_RUN') {
    url = `https://run.googleapis.com/v2/projects/${projectId}/locations/${resource.zone}/services/${resource.name}?updateMask=labels`;
    method = 'PATCH';
    body = { labels: newLabels }; 
  } else if (resource.type === 'CLOUD_SQL') {
    url = `${SQL_ADMIN_URL}/${projectId}/instances/${resource.name}`;
    method = 'PATCH';
    body = { settings: { userLabels: newLabels } };
  } else {
    throw new Error(`Updating labels for type ${resource.type} not supported yet.`);
  }
  
  const response = await fetchWithBackoff(url, {
    method: method,
    headers: {
      Authorization: `Bearer ${accessToken}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(body),
  });

   if (!response.ok) {
    const errorMessage = await parseGcpError(response);
    throw new Error(errorMessage);
  }
  
  return response.json();
};

export const fetchGcpAuditLogs = async (
  projectId: string,
  accessToken: string,
  pageSize = 50
): Promise<LogEntry[]> => {
  try {
    const response = await fetchWithBackoff(LOGGING_URL, {
      method: 'POST',
      headers: { 
        'Authorization': `Bearer ${accessToken}`, 
        'Content-Type': 'application/json' 
      },
      body: JSON.stringify({
        resourceNames: [`projects/${projectId}`],
        filter: `protoPayload.serviceName=("compute.googleapis.com" OR "run.googleapis.com" OR "cloudsql.googleapis.com") AND logName:"projects/${projectId}/logs/cloudaudit.googleapis.com%2Factivity"`,
        orderBy: 'timestamp desc',
        pageSize
      })
    });

    if (!response.ok) {
        if (response.status === 401) throw new Error("Authentication Failed (401): Session expired.");
        console.warn('Failed to fetch GCP logs', response.statusText);
        return [];
    }

    const data = await response.json();
    if (!data.entries) return [];

    return data.entries.map((e: any) => {
      const payload = e.protoPayload || {};
      const method = payload.methodName || 'Unknown Action';
      const principal = payload.authenticationInfo?.principalEmail || 'Unknown Actor';
      const resourceName = payload.resourceName?.split('/').pop() || 'Unknown Resource';
      let severity = e.severity || 'INFO';
      
      // Extraction of Rich Data
      const callerIp = payload.requestMetadata?.callerIp;
      const userAgent = payload.requestMetadata?.callerSuppliedUserAgent;
      const status = payload.status ? { code: payload.status.code, message: payload.status.message } : undefined;
      const location = payload.resourceLocation?.currentLocations?.[0];

      return {
        id: e.insertId,
        timestamp: new Date(e.timestamp),
        severity: severity,
        methodName: method,
        principalEmail: principal,
        resourceName: resourceName,
        summary: `${method} on ${resourceName}`,
        source: 'GCP',
        callerIp,
        userAgent,
        status,
        location
      };
    });
  } catch (error) {
    if ((error as Error).message.includes('401')) throw error;
    console.error("Error fetching logs:", error);
    return [];
  }
};

export const fetchQuotas = async (
  projectId: string,
  accessToken: string
): Promise<QuotaEntry[]> => {
  // Fetch Compute Engine Quotas (Aggregated by Region)
  const fetchComputeQuotas = async () => {
    try {
      const url = `${BASE_URL}/${projectId}/regions`;
      const response = await fetchWithBackoff(url, {
        headers: { Authorization: `Bearer ${accessToken}` },
      });

      if (!response.ok) return [];

      const data = await response.json();
      if (!data.items) return [];

      const computeQuotas: QuotaEntry[] = [];
      data.items.forEach((region: any) => {
          if (region.quotas) {
              region.quotas.forEach((q: any) => {
                  if (q.limit > 0 && q.usage > 0) { 
                      const percent = (q.usage / q.limit) * 100;
                      computeQuotas.push({
                          metric: q.metric,
                          limit: q.limit,
                          usage: q.usage,
                          region: region.name,
                          percentage: percent
                      });
                  }
              });
          }
      });
      return computeQuotas;
    } catch (e) {
      console.error("Compute Quota Fetch Failed", e);
      return [];
    }
  };

  // Mock secondary quota source (e.g. Cloud SQL or Global Service Quotas)
  // In a real app, this would call Service Usage API or specific Cloud SQL limits
  const fetchDatabaseQuotas = async () => {
     // Simulating an async fetch for DB quotas in parallel
     await new Promise(resolve => setTimeout(resolve, 500)); 
     return [
       { metric: 'CLOUD_SQL_CPU_REGION', limit: 100, usage: 85, region: 'us-central1', percentage: 85 },
       { metric: 'CLOUD_SQL_STORAGE_TB', limit: 50, usage: 10, region: 'global', percentage: 20 }
     ] as QuotaEntry[];
  };

  try {
    // Parallel Execution of distinct quota sources
    const [compute, database] = await Promise.all([
       fetchComputeQuotas(),
       fetchDatabaseQuotas()
    ]);

    return [...compute, ...database].sort((a, b) => b.percentage - a.percentage);
  } catch (e) {
    console.error("Quota fetch failed:", e);
    return [];
  }
};
